{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from utils.mlflow_saving import mlflow_save_result\n",
    "from utils.read import reshape_new_to_old_format, reshape_old_to_new_format\n",
    "\n",
    "\n",
    "# TODO: Verbose\n",
    "# TODO: Feature unit-test:\n",
    "# TODO: Describe Function: Get Experiment class information\n",
    "class Experiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        clasifier=None,\n",
    "        dataset=None,\n",
    "        augment={\"name\": str(None), \"params\": str(None)},\n",
    "        verbose=0,\n",
    "    ):\n",
    "        self.clasifier = clasifier\n",
    "        self.dataset = dataset\n",
    "        self.augment = augment\n",
    "        self.y_pred = None\n",
    "        self.evaluation_metric = {}\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def load_UCR_dataset(self, dataset: str = None):\n",
    "        dataset_name = self.dataset if self.dataset else dataset\n",
    "        x_train, y_train = load_UCR_UEA_dataset(\n",
    "            dataset_name, split=\"train\", return_X_y=True, return_type=\"numpy2D\"\n",
    "        )\n",
    "        x_test, y_test = load_UCR_UEA_dataset(\n",
    "            dataset_name, split=\"test\", return_X_y=True, return_type=\"numpy2D\"\n",
    "        )\n",
    "        # TODO: Data Inconsistency with interface\n",
    "        self.dataset = {\n",
    "            \"name\": dataset_name,\n",
    "            \"x_train\": x_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"x_test\": x_test,\n",
    "            \"y_test\": y_test,\n",
    "        }\n",
    "\n",
    "    def augmentation(self):\n",
    "        if self.augment[\"name\"] == \"None\":\n",
    "            return\n",
    "        x_train = reshape_new_to_old_format(self.dataset[\"x_train\"])\n",
    "        x_test = reshape_new_to_old_format(self.dataset[\"x_test\"])\n",
    "\n",
    "        if self.augment.get('enter_label') == True:\n",
    "            x_train_aug = self.augment[\"function\"](x_train, self.dataset[\"y_train\"], **self.augment[\"params\"])\n",
    "            x_test_aug = self.augment[\"function\"](x_test, self.dataset[\"y_test\"], **self.augment[\"params\"])\n",
    "\n",
    "        else:\n",
    "            x_train_aug = self.augment[\"function\"](x_train, **self.augment[\"params\"])\n",
    "            x_test_aug = self.augment[\"function\"](x_test, **self.augment[\"params\"])\n",
    "\n",
    "        # Concat original or not\n",
    "        if self.augment.get('concat_original') == True:\n",
    "            x_train_aug = np.concatenate((x_train_aug, x_train), axis=0)\n",
    "            x_test_aug = np.concatenate((x_test_aug, x_test), axis=0)\n",
    "            self.dataset[\"y_train\"] = np.concatenate((self.dataset[\"y_train\"], self.dataset[\"y_train\"]), axis=0)\n",
    "            self.dataset[\"y_test\"] = np.concatenate((self.dataset[\"y_test\"], self.dataset[\"y_test\"]), axis=0)\n",
    "\n",
    "        self.dataset[\"x_train_aug\"] = reshape_old_to_new_format(x_train_aug)\n",
    "        self.dataset[\"x_test_aug\"] = reshape_old_to_new_format(x_test_aug)\n",
    "\n",
    "    def train_classier(self):\n",
    "        if (self.dataset.get('x_train_aug').all() == None) or (self.dataset.get('x_test_aug').all() == None):\n",
    "            self.clasifier[\"function\"].fit(self.dataset[\"x_train\"], self.dataset[\"y_train\"])\n",
    "        else:\n",
    "            print(f'Training Shape: {self.dataset[\"x_train_aug\"].shape}, {self.dataset[\"y_train\"].shape}')\n",
    "            self.clasifier[\"function\"].fit(self.dataset[\"x_train_aug\"], self.dataset[\"y_train\"])\n",
    "\n",
    "    def predict(self):\n",
    "        self.y_pred = self.clasifier[\"function\"].predict(self.dataset[\"x_test_aug\"])\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.evaluation_metric[\"accuracy\"] = accuracy_score(\n",
    "            self.dataset[\"y_test\"], self.y_pred\n",
    "        )\n",
    "        (\n",
    "            self.evaluation_metric[\"precision\"],\n",
    "            self.evaluation_metric[\"recall\"],\n",
    "            self.evaluation_metric[\"fbeta\"],\n",
    "            self.evaluation_metric[\"support\"],\n",
    "        ) = precision_recall_fscore_support(self.dataset[\"y_test\"], self.y_pred)\n",
    "\n",
    "    def save_result(self):\n",
    "        mlflow_save_result(\n",
    "            {\"accuracy\": self.evaluation_metric[\"accuracy\"]},\n",
    "            {\"model\": self.clasifier[\"name\"]},\n",
    "            {\n",
    "                \"dataset\": self.dataset[\"name\"],\n",
    "                \"datapoint_shape\": str(self.dataset[\"x_train_aug\"].shape)\n",
    "                + \"x\"\n",
    "                + str(self.dataset[\"x_test\"].shape),\n",
    "                \"number_of_class\": len(set(list(self.dataset[\"y_test\"]))),\n",
    "            },\n",
    "            {\n",
    "                \"augmentation\": {\n",
    "                    \"name\": self.augment[\"name\"],\n",
    "                    \"params\": self.augment[\"params\"],\n",
    "                },\n",
    "            },\n",
    "            # [{\"data\": self.augment[\"params\"], \"file_name\": \"dict/augmentation.json\"}],\n",
    "        )\n",
    "        print(f'{self.clasifier[\"name\"]}, {self.dataset[\"name\"]}, ({self.augment[\"name\"]}, {self.augment[\"params\"]}) DONE')\n",
    "\n",
    "    def run_all(self):\n",
    "        self.load_UCR_dataset()\n",
    "        self.augmentation()\n",
    "        self.train_classier()\n",
    "        self.predict()\n",
    "        self.evaluate()\n",
    "        # self.save_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from experiment.Experiment import Experiment\n",
    "# from experiment.ExperimentSet import ExperimentSet\n",
    "from utils.read import read_UCR_dataset_name\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (750, 1, 720), f(750,)\n"
     ]
    }
   ],
   "source": [
    "from time_series_augmentation.utils.pun_augmentation import window_slice\n",
    "\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'ScreenType'\n",
    "augment = {'name': 'window_slice_py', 'function': window_slice,'params': {}, 'concat_original': True}\n",
    "experiments = Experiment(classifer, dataset, augment)\n",
    "experiments.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.43066666666666664,\n",
       " 'precision': array([0.3930131 , 0.40248963, 0.48571429]),\n",
       " 'recall': array([0.36 , 0.388, 0.544]),\n",
       " 'fbeta': array([0.37578288, 0.39511202, 0.51320755]),\n",
       " 'support': array([250, 250, 250])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments.evaluation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (375, 1, 720), f(375,)\n"
     ]
    }
   ],
   "source": [
    "from time_series_augmentation.utils.pun_augmentation import window_slice\n",
    "\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'ScreenType'\n",
    "augment = {'name': 'window_slice_py', 'function': window_slice,'params': {}, 'concat_original': False}\n",
    "experiments = Experiment(classifer, dataset, augment)\n",
    "experiments.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.45866666666666667,\n",
       " 'precision': array([0.43410853, 0.4368932 , 0.4965035 ]),\n",
       " 'recall': array([0.448, 0.36 , 0.568]),\n",
       " 'fbeta': array([0.44094488, 0.39473684, 0.52985075]),\n",
       " 'support': array([125, 125, 125])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments.evaluation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd4f62c38baa1ece4ec6c2534f3f788090e745d10d9094b86edc39a20217e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
