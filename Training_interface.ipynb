{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "from experiment.Experiment import Experiment\n",
    "from experiment.ExperimentSet import ExperimentSet\n",
    "from utils.read import read_UCR_dataset_name\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAdiac\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m training_one \u001b[39m=\u001b[39m Experiment(classifer, dataset)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m training_one\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:117\u001b[0m, in \u001b[0;36mExperiment.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_UCR_dataset()\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation()\n\u001b[0;32m--> 117\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_classier()\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict()\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:71\u001b[0m, in \u001b[0;36mExperiment.train_classier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_classier\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mx_train_aug\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mall() \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mx_test_aug\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mall() \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     72\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasifier[\u001b[39m\"\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39mx_train\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     73\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'Adiac'\n",
    "training_one = Experiment(classifer, dataset)\n",
    "training_one.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: c062e3dea15e49c3b289a3abe4238bca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pongpanod.Sa/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# AUGMENTED\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'Adiac'\n",
    "augment = {'name':'jitter', 'function': jitter, 'params': {'sigma': 0.05}}\n",
    "training_two = Experiment(classifer, dataset, augment)\n",
    "training_two.run_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = read_UCR_dataset_name()\n",
    "experiment_set = ExperimentSet(classifer, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_set.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTED\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = read_UCR_dataset_name()\n",
    "augment = {'name':'jitter', 'function': jitter, 'params': {'sigma': 0.05}}\n",
    "experiment_set = ExperimentSet(classifer, dataset, augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dataset name =A is not available on extract path =None. Nor is it available on https://timeseriesclassification.com/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:102\u001b[0m, in \u001b[0;36m_download_and_extract\u001b[0;34m(url, extract_path)\u001b[0m\n\u001b[1;32m    101\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(extract_path)\n\u001b[0;32m--> 102\u001b[0m zipfile\u001b[39m.\u001b[39;49mZipFile(zip_file_name, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mextractall(extract_path)\n\u001b[1;32m    103\u001b[0m shutil\u001b[39m.\u001b[39mrmtree(dl_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/zipfile.py:1267\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m-> 1267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_RealGetContents()\n\u001b[1;32m   1268\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1269\u001b[0m     \u001b[39m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[39m# even if no files are added to the archive\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/zipfile.py:1334\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1334\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:202\u001b[0m, in \u001b[0;36m_load_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     _download_and_extract(\n\u001b[1;32m    203\u001b[0m         url,\n\u001b[1;32m    204\u001b[0m         extract_path\u001b[39m=\u001b[39;49mextract_path,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:109\u001b[0m, in \u001b[0;36m_download_and_extract\u001b[0;34m(url, extract_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m     shutil\u001b[39m.\u001b[39mrmtree(extract_path)\n\u001b[0;32m--> 109\u001b[0m \u001b[39mraise\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile(\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCould not unzip dataset. Please make sure the URL is valid.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m )\n",
      "\u001b[0;31mBadZipFile\u001b[0m: Could not unzip dataset. Please make sure the URL is valid.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m experiment_set\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/ExperimentSet.py:15\u001b[0m, in \u001b[0;36mExperimentSet.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m dataset \u001b[39m=\u001b[39m i\n\u001b[1;32m     14\u001b[0m experiments \u001b[39m=\u001b[39m Experiment(classifer, dataset)\n\u001b[0;32m---> 15\u001b[0m experiments\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:79\u001b[0m, in \u001b[0;36mExperiment.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_all\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_UCR_dataset()\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation()\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_classier()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:22\u001b[0m, in \u001b[0;36mExperiment.load_UCR_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_UCR_dataset\u001b[39m(\u001b[39mself\u001b[39m, dataset:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     dataset_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39melse\u001b[39;00m dataset\n\u001b[0;32m---> 22\u001b[0m     x_train, y_train \u001b[39m=\u001b[39m load_UCR_UEA_dataset(\n\u001b[1;32m     23\u001b[0m         dataset_name, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, return_X_y\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnumpy2D\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     x_test, y_test \u001b[39m=\u001b[39m load_UCR_UEA_dataset(\n\u001b[1;32m     26\u001b[0m         dataset_name, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, return_X_y\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy2D\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[39m# TODO: Data Inconsistency with interface\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_single_problem_loaders.py:119\u001b[0m, in \u001b[0;36mload_UCR_UEA_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_UCR_UEA_dataset\u001b[39m(\n\u001b[1;32m     63\u001b[0m     name, split\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_X_y\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extract_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m ):\n\u001b[1;32m     65\u001b[0m     \u001b[39m\"\"\"Load dataset from UCR UEA time series archive.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    Downloads and extracts dataset if not already downloaded. Data is assumed to be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m    >>> X, y = load_UCR_UEA_dataset(name=\"ArrowHead\")\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_dataset(name, split, return_X_y, return_type, extract_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:207\u001b[0m, in \u001b[0;36m_load_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m    202\u001b[0m             _download_and_extract(\n\u001b[1;32m    203\u001b[0m                 url,\n\u001b[1;32m    204\u001b[0m                 extract_path\u001b[39m=\u001b[39mextract_path,\n\u001b[1;32m    205\u001b[0m             )\n\u001b[1;32m    206\u001b[0m         \u001b[39mexcept\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid dataset name =\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is not available on extract path =\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mextract_path\u001b[39m}\u001b[39;00m\u001b[39m. Nor is it available on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://timeseriesclassification.com/.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m _load_provided_dataset(\n\u001b[1;32m    214\u001b[0m     name, split, return_X_y, return_type, local_module, local_dirname\n\u001b[1;32m    215\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dataset name =A is not available on extract path =None. Nor is it available on https://timeseriesclassification.com/."
     ]
    }
   ],
   "source": [
    "experiment_set.run_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from experiment.Experiment import Experiment\n",
    "from experiment.ExperimentSet import ExperimentSet\n",
    "from utils.read import read_UCR_dataset_name\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m read_UCR_dataset_name():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     training_one \u001b[39m=\u001b[39m Experiment(classifer, i)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/Training_interface.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     training_one\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:116\u001b[0m, in \u001b[0;36mExperiment.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_UCR_dataset()\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation()\n\u001b[0;32m--> 116\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_classier()\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict()\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:75\u001b[0m, in \u001b[0;36mExperiment.train_classier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasifier[\u001b[39m\"\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39mx_train\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasifier[\u001b[39m\"\u001b[39;49m\u001b[39mfunction\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39m\"\u001b[39;49m\u001b[39mx_train_aug\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39m\"\u001b[39;49m\u001b[39my_train\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/base.py:191\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[39m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_time_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)) \u001b[39m-\u001b[39m start\n\u001b[1;32m    194\u001b[0m \u001b[39m# this should happen last\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/dictionary_based/_tde.py:333\u001b[0m, in \u001b[0;36mTemporalDictionaryEnsemble._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    321\u001b[0m y_subsample \u001b[39m=\u001b[39m y[subsample]\n\u001b[1;32m    323\u001b[0m tde \u001b[39m=\u001b[39m IndividualTDE(\n\u001b[1;32m    324\u001b[0m     \u001b[39m*\u001b[39mparameters,\n\u001b[1;32m    325\u001b[0m     alphabet_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alphabet_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[1;32m    332\u001b[0m )\n\u001b[0;32m--> 333\u001b[0m tde\u001b[39m.\u001b[39;49mfit(X_subsample, y_subsample)\n\u001b[1;32m    334\u001b[0m tde\u001b[39m.\u001b[39m_subsample \u001b[39m=\u001b[39m subsample\n\u001b[1;32m    336\u001b[0m tde\u001b[39m.\u001b[39m_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_individual_train_acc(\n\u001b[1;32m    337\u001b[0m     tde,\n\u001b[1;32m    338\u001b[0m     y_subsample,\n\u001b[1;32m    339\u001b[0m     subsample_size,\n\u001b[1;32m    340\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m num_classifiers \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_ensemble_size \u001b[39melse\u001b[39;00m lowest_acc,\n\u001b[1;32m    341\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/base.py:191\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[39m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_time_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)) \u001b[39m-\u001b[39m start\n\u001b[1;32m    194\u001b[0m \u001b[39m# this should happen last\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/dictionary_based/_tde.py:828\u001b[0m, in \u001b[0;36mIndividualTDE._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformers\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    812\u001b[0m         SFA(\n\u001b[1;32m    813\u001b[0m             word_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m     )\n\u001b[0;32m--> 828\u001b[0m     sfa \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformers[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mfit_transform(X, y)\n\u001b[1;32m    829\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformed_data \u001b[39m=\u001b[39m sfa[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/base.py:554\u001b[0m, in \u001b[0;36mBaseTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39m\"\"\"Fit to data, then transform it.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \n\u001b[1;32m    499\u001b[0m \u001b[39mFits the transformer to X and y and returns a transformed version of X.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39m        Example: i-th instance of the output is the i-th window running over `X`\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39m# Non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[39m# method is possible for a given algorithm.\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y)\u001b[39m.\u001b[39;49mtransform(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/base.py:483\u001b[0m, in \u001b[0;36mBaseTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    480\u001b[0m X_inner, y_inner, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, return_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X_inner, VectorizedDF):\n\u001b[0;32m--> 483\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X\u001b[39m=\u001b[39;49mX_inner, y\u001b[39m=\u001b[39;49my_inner)\n\u001b[1;32m    484\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m     \u001b[39m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m, X\u001b[39m=\u001b[39mX_inner, y\u001b[39m=\u001b[39my_inner)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/panel/dictionary_based/_sfa.py:274\u001b[0m, in \u001b[0;36mSFA._transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    273\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39mNumbaTypeSafetyWarning)\n\u001b[0;32m--> 274\u001b[0m     transform \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    275\u001b[0m         delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_case)(\n\u001b[1;32m    276\u001b[0m             X[i, :],\n\u001b[1;32m    277\u001b[0m             supplied_dft\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinning_dft[i] \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeep_binning_dft \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m         \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m dim, words \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mtransform)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_words:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/panel/dictionary_based/_sfa.py:373\u001b[0m, in \u001b[0;36mSFA._transform_case\u001b[0;34m(self, X, supplied_dft)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m                 bigram \u001b[39m=\u001b[39m (bigram \u001b[39m<<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevel_bits) \u001b[39m|\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 373\u001b[0m         bag[bigram] \u001b[39m=\u001b[39m bag\u001b[39m.\u001b[39;49mget(bigram, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_grams:\n\u001b[1;32m    376\u001b[0m     \u001b[39m# creates skip-grams, skipping every (s-1)-th word in-between\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/numba/typed/typeddict.py:194\u001b[0m, in \u001b[0;36mDict.get\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_typed:\n\u001b[1;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m _get(\u001b[39mself\u001b[39;49m, key, default)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sktime.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "\n",
    "# BASELINE\n",
    "classifer = {'name': 'TDE', 'function': TemporalDictionaryEnsemble()}\n",
    "for i in read_UCR_dataset_name():\n",
    "    training_one = Experiment(classifer, i)\n",
    "    training_one.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = read_UCR_dataset_name(mySelection=0.0)\n",
    "dataset_first_half = datasets[:40]\n",
    "dataset_second_half = datasets[40:]\n",
    "\n",
    "dataset_first_half_10 = dataset_first_half[11:]\n",
    "dataset_first_half_29 = dataset_first_half[30:]\n",
    "\n",
    "dataset_second_half_13 = dataset_second_half[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.33it/s]\n",
      "100%|██████████| 150/150 [00:34<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, GunPoint, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:30<00:00,  2.35s/it]\n",
      "100%|██████████| 64/64 [02:30<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, Herring, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:50<00:00, 11.99it/s]\n",
      "100%|██████████| 291/291 [00:24<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, MiddlePhalanxOutlineCorrect, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:49<00:00, 12.01it/s]\n",
      "100%|██████████| 291/291 [00:24<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, ProximalPhalanxOutlineCorrect, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:21<00:00,  1.68it/s]\n",
      "100%|██████████| 175/175 [01:43<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, ArrowHead, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:33<00:00, 12.00it/s]\n",
      "100%|██████████| 139/139 [00:11<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, DistalPhalanxOutlineAgeGroup, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:33<00:00, 11.96it/s]\n",
      "100%|██████████| 154/154 [00:12<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, MiddlePhalanxOutlineAgeGroup, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:01<00:00, 59.34it/s]\n",
      "100%|██████████| 1029/1029 [00:17<00:00, 60.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, ItalyPowerDemand, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [27:33<00:00,  4.41s/it]\n",
      "100%|██████████| 375/375 [27:29<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, LargeKitchenAppliances, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:33<00:00, 12.05it/s]\n",
      "100%|██████████| 205/205 [00:16<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, ProximalPhalanxOutlineAgeGroup, (wdba, {'batch_size': 9}) DONE\n"
     ]
    }
   ],
   "source": [
    "from time_series_augmentation.utils.pun_augmentation import wdba\n",
    "\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "# datasets = read_UCR_dataset_name(mySelection=0.0)\n",
    "datasets = dataset_first_half_29\n",
    "augment = {'name': 'wdba', 'function': wdba, 'concat_original': False, 'enter_label': True, 'params': {'batch_size': [9]}}\n",
    "experiment_set = ExperimentSet(classifer, datasets, augment)\n",
    "experiment_set.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8926/8926 [18:12<00:00,  8.17it/s]\n",
      "100%|██████████| 7711/7711 [15:46<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, ElectricDevices, (wdba, {'batch_size': 9}) DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:33:44<00:00,  9.22s/it] \n",
      "100%|██████████| 8236/8236 [100:21:40<00:00, 43.87s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, StarLightCurves, (wdba, {'batch_size': 9}) DONE\n"
     ]
    }
   ],
   "source": [
    "from time_series_augmentation.utils.pun_augmentation import wdba\n",
    "\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = ['ElectricDevices', 'StarLightCurves']\n",
    "augment = {'name': 'wdba', 'function': wdba, 'concat_original': False, 'enter_label': True, 'params': {'batch_size': [9]}}\n",
    "experiment_set = ExperimentSet(classifer, datasets, augment)\n",
    "experiment_set.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd4f62c38baa1ece4ec6c2534f3f788090e745d10d9094b86edc39a20217e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
