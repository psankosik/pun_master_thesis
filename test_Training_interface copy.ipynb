{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.Experiment import Experiment\n",
    "from experiment.ExperimentSet import ExperimentSet\n",
    "from utils.read import read_UCR_dataset_name\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from time_series_augmentation.utils.augmentation import jitter, scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: 27f8b9624c0e49adba1e88c4de96fcea\n"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'Adiac'\n",
    "training_one = Experiment(classifer, dataset)\n",
    "training_one.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: c062e3dea15e49c3b289a3abe4238bca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pongpanod.Sa/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# AUGMENTED\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "dataset = 'Adiac'\n",
    "augment = {'name':'jitter', 'function': jitter, 'params': {'sigma': 0.05}}\n",
    "training_two = Experiment(classifer, dataset, augment)\n",
    "training_two.run_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = read_UCR_dataset_name()\n",
    "experiment_set = ExperimentSet(classifer, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_set.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTED\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = read_UCR_dataset_name()\n",
    "augment = {'name':'jitter', 'function': jitter, 'params': {'sigma': 0.05}}\n",
    "experiment_set = ExperimentSet(classifer, dataset, augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dataset name =A is not available on extract path =None. Nor is it available on https://timeseriesclassification.com/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:102\u001b[0m, in \u001b[0;36m_download_and_extract\u001b[0;34m(url, extract_path)\u001b[0m\n\u001b[1;32m    101\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(extract_path)\n\u001b[0;32m--> 102\u001b[0m zipfile\u001b[39m.\u001b[39;49mZipFile(zip_file_name, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mextractall(extract_path)\n\u001b[1;32m    103\u001b[0m shutil\u001b[39m.\u001b[39mrmtree(dl_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/zipfile.py:1267\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m-> 1267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_RealGetContents()\n\u001b[1;32m   1268\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1269\u001b[0m     \u001b[39m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[39m# even if no files are added to the archive\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/zipfile.py:1334\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1334\u001b[0m     \u001b[39mraise\u001b[39;00m BadZipFile(\u001b[39m\"\u001b[39m\u001b[39mFile is not a zip file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:202\u001b[0m, in \u001b[0;36m_load_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     _download_and_extract(\n\u001b[1;32m    203\u001b[0m         url,\n\u001b[1;32m    204\u001b[0m         extract_path\u001b[39m=\u001b[39;49mextract_path,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:109\u001b[0m, in \u001b[0;36m_download_and_extract\u001b[0;34m(url, extract_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m     shutil\u001b[39m.\u001b[39mrmtree(extract_path)\n\u001b[0;32m--> 109\u001b[0m \u001b[39mraise\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile(\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCould not unzip dataset. Please make sure the URL is valid.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m )\n",
      "\u001b[0;31mBadZipFile\u001b[0m: Could not unzip dataset. Please make sure the URL is valid.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m experiment_set\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/ExperimentSet.py:15\u001b[0m, in \u001b[0;36mExperimentSet.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m dataset \u001b[39m=\u001b[39m i\n\u001b[1;32m     14\u001b[0m experiments \u001b[39m=\u001b[39m Experiment(classifer, dataset)\n\u001b[0;32m---> 15\u001b[0m experiments\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:79\u001b[0m, in \u001b[0;36mExperiment.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_all\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_UCR_dataset()\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation()\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_classier()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:22\u001b[0m, in \u001b[0;36mExperiment.load_UCR_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_UCR_dataset\u001b[39m(\u001b[39mself\u001b[39m, dataset:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     dataset_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39melse\u001b[39;00m dataset\n\u001b[0;32m---> 22\u001b[0m     x_train, y_train \u001b[39m=\u001b[39m load_UCR_UEA_dataset(\n\u001b[1;32m     23\u001b[0m         dataset_name, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, return_X_y\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnumpy2D\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     x_test, y_test \u001b[39m=\u001b[39m load_UCR_UEA_dataset(\n\u001b[1;32m     26\u001b[0m         dataset_name, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, return_X_y\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy2D\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[39m# TODO: Data Inconsistency with interface\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_single_problem_loaders.py:119\u001b[0m, in \u001b[0;36mload_UCR_UEA_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_UCR_UEA_dataset\u001b[39m(\n\u001b[1;32m     63\u001b[0m     name, split\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_X_y\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extract_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m ):\n\u001b[1;32m     65\u001b[0m     \u001b[39m\"\"\"Load dataset from UCR UEA time series archive.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    Downloads and extracts dataset if not already downloaded. Data is assumed to be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m    >>> X, y = load_UCR_UEA_dataset(name=\"ArrowHead\")\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_dataset(name, split, return_X_y, return_type, extract_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/datasets/_data_io.py:207\u001b[0m, in \u001b[0;36m_load_dataset\u001b[0;34m(name, split, return_X_y, return_type, extract_path)\u001b[0m\n\u001b[1;32m    202\u001b[0m             _download_and_extract(\n\u001b[1;32m    203\u001b[0m                 url,\n\u001b[1;32m    204\u001b[0m                 extract_path\u001b[39m=\u001b[39mextract_path,\n\u001b[1;32m    205\u001b[0m             )\n\u001b[1;32m    206\u001b[0m         \u001b[39mexcept\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid dataset name =\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is not available on extract path =\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mextract_path\u001b[39m}\u001b[39;00m\u001b[39m. Nor is it available on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://timeseriesclassification.com/.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m _load_provided_dataset(\n\u001b[1;32m    214\u001b[0m     name, split, return_X_y, return_type, local_module, local_dirname\n\u001b[1;32m    215\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dataset name =A is not available on extract path =None. Nor is it available on https://timeseriesclassification.com/."
     ]
    }
   ],
   "source": [
    "experiment_set.run_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "from experiment.Experiment import Experiment\n",
    "# from experiment.ExperimentSet import ExperimentSet\n",
    "from utils.read import read_UCR_dataset_name\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from time_series_augmentation.utils.augmentation import jitter, scaling, magnitude_warp, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.Experiment import Experiment\n",
    "from utils.hyperparameter import get_successors\n",
    "\n",
    "class ExperimentSet:\n",
    "    def __init__(self, classier, datasets=None, augments=None, verbose=0):\n",
    "        self.classier = classier\n",
    "        self.datasets = datasets\n",
    "        self.augments = augments\n",
    "\n",
    "    def run_all(self):\n",
    "        params_grid = get_successors(self.augments['params'])\n",
    "        for param in params_grid:\n",
    "            result = {}\n",
    "            for d in param:\n",
    "                result.update(d)\n",
    "\n",
    "            for dataset in self.datasets:\n",
    "                augment = {'name': self.augments['name'], 'function': self.augments['function'], 'params': result}\n",
    "                experiments = Experiment(self.classier, dataset, augment)\n",
    "                experiments.run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minirocket, Adiac, (permutaty, {'max_segments': 2, 'seg_mode': 'equal'}) DONE\n",
      "minirocket, ArrowHead, (permutaty, {'max_segments': 2, 'seg_mode': 'equal'}) DONE\n",
      "minirocket, Adiac, (permutaty, {'max_segments': 2, 'seg_mode': 'random'}) DONE\n",
      "minirocket, ArrowHead, (permutaty, {'max_segments': 2, 'seg_mode': 'random'}) DONE\n",
      "minirocket, Adiac, (permutaty, {'max_segments': 3, 'seg_mode': 'equal'}) DONE\n",
      "minirocket, ArrowHead, (permutaty, {'max_segments': 3, 'seg_mode': 'equal'}) DONE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface copy.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m augment \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mpermutaty\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m'\u001b[39m: permutation, \u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mmax_segments\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mseg_mode\u001b[39m\u001b[39m\"\u001b[39m:[\u001b[39m\"\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m]}}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m experiment_set \u001b[39m=\u001b[39m ExperimentSet(classifer, datasets, augment)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m experiment_set\u001b[39m.\u001b[39;49mrun_all()\n",
      "\u001b[1;32m/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface copy.ipynb Cell 15\u001b[0m in \u001b[0;36mExperimentSet.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m augment \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugments[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugments[\u001b[39m'\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: result}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m experiments \u001b[39m=\u001b[39m Experiment(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassier, dataset, augment)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Pongpanod.Sa/Desktop/cu/thesis/coding/pun_master_thesis/test_Training_interface%20copy.ipynb#X52sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m experiments\u001b[39m.\u001b[39;49mrun_all()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:97\u001b[0m, in \u001b[0;36mExperiment.run_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation()\n\u001b[1;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_classier()\n\u001b[0;32m---> 97\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict()\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_result()\n",
      "File \u001b[0;32m~/Desktop/cu/thesis/coding/pun_master_thesis/experiment/Experiment.py:59\u001b[0m, in \u001b[0;36mExperiment.predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasifier[\u001b[39m\"\u001b[39;49m\u001b[39mfunction\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39m\"\u001b[39;49m\u001b[39mx_test\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/base.py:228\u001b[0m, in \u001b[0;36mBaseClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_class_y_pred(X, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[39m# call internal _predict_proba\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/_delegate.py:96\u001b[0m, in \u001b[0;36m_DelegatedClassifier._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m\"\"\"Predict labels for sequences in X.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[39mprivate _predict containing the core logic, called from predict\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m    indices correspond to instance indices in X\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_delegate()\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mX)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/base.py:228\u001b[0m, in \u001b[0;36mBaseClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_class_y_pred(X, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[39m# call internal _predict_proba\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/classification/compose/_pipeline.py:525\u001b[0m, in \u001b[0;36mSklearnClassifierPipeline._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    513\u001b[0m     \u001b[39m\"\"\"Predict labels for sequences in X.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \n\u001b[1;32m    515\u001b[0m \u001b[39m    core logic\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39m    y : predictions of labels for X, np.ndarray\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformers_\u001b[39m.\u001b[39;49mtransform(X\u001b[39m=\u001b[39;49mX)\n\u001b[1;32m    526\u001b[0m     Xt_sklearn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_X_to_sklearn(Xt)\n\u001b[1;32m    527\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_\u001b[39m.\u001b[39mpredict(Xt_sklearn)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/base.py:483\u001b[0m, in \u001b[0;36mBaseTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    480\u001b[0m X_inner, y_inner, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, return_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X_inner, VectorizedDF):\n\u001b[0;32m--> 483\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X\u001b[39m=\u001b[39;49mX_inner, y\u001b[39m=\u001b[39;49my_inner)\n\u001b[1;32m    484\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m     \u001b[39m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m, X\u001b[39m=\u001b[39mX_inner, y\u001b[39m=\u001b[39my_inner)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/compose.py:338\u001b[0m, in \u001b[0;36mTransformerPipeline._transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m _, transformer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps_:\n\u001b[1;32m    337\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_tag(\u001b[39m\"\u001b[39m\u001b[39mfit_is_empty\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 338\u001b[0m         Xt \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mtransform(X\u001b[39m=\u001b[39;49mXt, y\u001b[39m=\u001b[39;49my)\n\u001b[1;32m    339\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m         Xt \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X\u001b[39m=\u001b[39mXt, y\u001b[39m=\u001b[39my)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/base.py:483\u001b[0m, in \u001b[0;36mBaseTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    480\u001b[0m X_inner, y_inner, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, return_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X_inner, VectorizedDF):\n\u001b[0;32m--> 483\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X\u001b[39m=\u001b[39;49mX_inner, y\u001b[39m=\u001b[39;49my_inner)\n\u001b[1;32m    484\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m     \u001b[39m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m, X\u001b[39m=\u001b[39mX_inner, y\u001b[39m=\u001b[39my_inner)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/sktime/transformations/panel/rocket/_minirocket.py:143\u001b[0m, in \u001b[0;36mMiniRocket._transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    141\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    142\u001b[0m set_num_threads(n_jobs)\n\u001b[0;32m--> 143\u001b[0m X_ \u001b[39m=\u001b[39m _transform(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters)\n\u001b[1;32m    144\u001b[0m set_num_threads(prev_threads)\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(X_)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis3.10/lib/python3.10/site-packages/numba/core/serialize.py:29\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m _unpickled_memo \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m        unpickled object\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     key \u001b[39m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AUGMENTED\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "variation = 'minirocket'\n",
    "classifer = {'name':variation, 'function': RocketClassifier(rocket_transform=variation)}\n",
    "datasets = read_UCR_dataset_name()[:2]\n",
    "augment = {'name':'permutaty', 'function': permutation, 'params': {'max_segments':[2,3,4,5,6], \"seg_mode\":[\"equal\", \"random\"]}}\n",
    "experiment_set = ExperimentSet(classifer, datasets, augment)\n",
    "experiment_set.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd4f62c38baa1ece4ec6c2534f3f788090e745d10d9094b86edc39a20217e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
